{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 6: Рекуррентные нейронные сети (RNNs)\n",
    "\n",
    "Это задание адаптиповано из Deep NLP Course at ABBYY (https://github.com/DanAnastasyev/DeepNLP-Course) с разрешения автора - Даниила Анастасьева. Спасибо ему огромное!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P59NYU98GCb9"
   },
   "outputs": [],
   "source": [
    "!pip3 -qq install torch==0.4.1\n",
    "!pip3 -qq install bokeh==0.13.0\n",
    "!pip3 -qq install gensim==3.6.0\n",
    "!pip3 -qq install nltk\n",
    "!pip3 -qq install scikit-learn==0.20.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8sVtGHmA9aBM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    from torch.cuda import FloatTensor, LongTensor\n",
    "else:\n",
    "    from torch import FloatTensor, LongTensor\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-6CNKM3b4hT1"
   },
   "source": [
    "# Рекуррентные нейронные сети (RNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O_XkoGNQUeGm"
   },
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QFEtWrS_4rUs"
   },
   "source": [
    "Мы рассмотрим применение рекуррентных сетей к задаче sequence labeling (последняя картинка).\n",
    "\n",
    "![RNN types](http://karpathy.github.io/assets/rnn/diags.jpeg)\n",
    "\n",
    "*From [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)*\n",
    "\n",
    "Самые популярные примеры для такой постановки задачи - Part-of-Speech Tagging и Named Entity Recognition.\n",
    "\n",
    "Мы порешаем сейчас POS Tagging для английского.\n",
    "\n",
    "Будем работать с таким набором тегов:\n",
    "- ADJ - adjective (new, good, high, ...)\n",
    "- ADP - adposition (on, of, at, ...)\n",
    "- ADV - adverb (really, already, still, ...)\n",
    "- CONJ - conjunction (and, or, but, ...)\n",
    "- DET - determiner, article (the, a, some, ...)\n",
    "- NOUN - noun (year, home, costs, ...)\n",
    "- NUM - numeral (twenty-four, fourth, 1991, ...)\n",
    "- PRT - particle (at, on, out, ...)\n",
    "- PRON - pronoun (he, their, her, ...)\n",
    "- VERB - verb (is, say, told, ...)\n",
    "- . - punctuation marks (. , ;)\n",
    "- X - other (ersatz, esprit, dunno, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EPIkKdFlHB-X"
   },
   "source": [
    "Скачаем данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TiA2dGmgF1rW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\tuxtender\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\tuxtender\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')\n",
    "\n",
    "data = nltk.corpus.brown.tagged_sents(tagset='universal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d93g_swyJA_V"
   },
   "source": [
    "Пример размеченного предложения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QstS4NO0L97c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The            \tDET\n",
      "Fulton         \tNOUN\n",
      "County         \tNOUN\n",
      "Grand          \tADJ\n",
      "Jury           \tNOUN\n",
      "said           \tVERB\n",
      "Friday         \tNOUN\n",
      "an             \tDET\n",
      "investigation  \tNOUN\n",
      "of             \tADP\n",
      "Atlanta's      \tNOUN\n",
      "recent         \tADJ\n",
      "primary        \tNOUN\n",
      "election       \tNOUN\n",
      "produced       \tVERB\n",
      "``             \t.\n",
      "no             \tDET\n",
      "evidence       \tNOUN\n",
      "''             \t.\n",
      "that           \tADP\n",
      "any            \tDET\n",
      "irregularities \tNOUN\n",
      "took           \tVERB\n",
      "place          \tNOUN\n",
      ".              \t.\n"
     ]
    }
   ],
   "source": [
    "for word, tag in data[0]:\n",
    "    print('{:15}\\t{}'.format(word, tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "epdW8u_YXcAv"
   },
   "source": [
    "Построим разбиение на train/val/test - наконец-то, всё как у нормальных людей.\n",
    "\n",
    "На train будем учиться, по val - подбирать параметры и делать всякие early stopping, а на test - принимать модель по ее финальному качеству."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xTai8Ta0lgwL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words count in train set: 739769\n",
      "Words count in val set: 130954\n",
      "Words count in test set: 290469\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.15, random_state=42)\n",
    "\n",
    "print('Words count in train set:', sum(len(sent) for sent in train_data))\n",
    "print('Words count in val set:', sum(len(sent) for sent in val_data))\n",
    "print('Words count in test set:', sum(len(sent) for sent in test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eChdLNGtXyP0"
   },
   "source": [
    "Построим маппинги из слов в индекс и из тега в индекс:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pCjwwDs6Zq9x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words in train = 45441. Tags = {'CONJ', 'VERB', 'NUM', 'X', 'ADJ', '.', 'PRT', 'NOUN', 'ADV', 'ADP', 'DET', 'PRON'}\n"
     ]
    }
   ],
   "source": [
    "words = {word for sample in train_data for word, tag in sample}\n",
    "word2ind = {word: ind + 1 for ind, word in enumerate(words)}\n",
    "word2ind['<pad>'] = 0\n",
    "\n",
    "tags = {tag for sample in train_data for word, tag in sample}\n",
    "tag2ind = {tag: ind + 1 for ind, tag in enumerate(tags)}\n",
    "tag2ind['<pad>'] = 0\n",
    "\n",
    "print('Unique words in train = {}. Tags = {}'.format(len(word2ind), tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "URC1B2nvPGFt"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "tag_distribution = Counter(tag for sample in train_data for _, tag in sample)\n",
    "tag_distribution = [tag_distribution[tag] for tag in tags]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "bar_width = 0.35\n",
    "plt.bar(np.arange(len(tags)), tag_distribution, bar_width, align='center', alpha=0.5)\n",
    "plt.xticks(np.arange(len(tags)), tags)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gArQwbzWWkgi"
   },
   "source": [
    "## Бейзлайн\n",
    "\n",
    "Какой самый простой теггер можно придумать? Давайте просто запоминать, какие теги самые вероятные для слова (или для последовательности):\n",
    "\n",
    "![tag-context](https://www.nltk.org/images/tag-context.png)  \n",
    "*From [Categorizing and Tagging Words, nltk](https://www.nltk.org/book/ch05.html)*\n",
    "\n",
    "На картинке показано, что для предсказания $t_n$ используются два предыдущих предсказанных тега + текущее слово. По корпусу считаются вероятность для $P(t_n| w_n, t_{n-1}, t_{n-2})$, выбирается тег с максимальной вероятностью.\n",
    "\n",
    "Более аккуратно такая идея реализована в Hidden Markov Models: по тренировочному корпусу вычисляются вероятности $P(w_n| t_n), P(t_n|t_{n-1}, t_{n-2})$ и максимизируется их произведение.\n",
    "\n",
    "Простейший вариант - униграммная модель, учитывающая только слово:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5rWmSToIaeAo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of unigram tagger = 92.62%\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "default_tagger = nltk.DefaultTagger('NN')\n",
    "\n",
    "unigram_tagger = nltk.UnigramTagger(train_data, backoff=default_tagger)\n",
    "print('Accuracy of unigram tagger = {:.2%}'.format(unigram_tagger.evaluate(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "07Ymb_MkbWsF"
   },
   "source": [
    "Добавим вероятности переходов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vjz_Rk0bbMyH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of bigram tagger = 93.42%\n"
     ]
    }
   ],
   "source": [
    "bigram_tagger = nltk.BigramTagger(train_data, backoff=unigram_tagger)\n",
    "print('Accuracy of bigram tagger = {:.2%}'.format(bigram_tagger.evaluate(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uWMw6QHvbaDd"
   },
   "source": [
    "Обратите внимание, что `backoff` важен:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8XCuxEBVbOY_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of trigram tagger = 23.33%\n"
     ]
    }
   ],
   "source": [
    "trigram_tagger = nltk.TrigramTagger(train_data)\n",
    "print('Accuracy of trigram tagger = {:.2%}'.format(trigram_tagger.evaluate(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4t3xyYd__8d-"
   },
   "source": [
    "## Увеличиваем контекст с рекуррентными сетями\n",
    "\n",
    "Униграмная модель работает на удивление хорошо, но мы же собрались учить сеточки.\n",
    "\n",
    "Омонимия - основная причина, почему униграмная модель плоха:  \n",
    "*“he cashed a check at the **bank**”*  \n",
    "vs  \n",
    "*“he sat on the **bank** of the river”*\n",
    "\n",
    "Поэтому нам очень полезно учитывать контекст при предсказании тега.\n",
    "\n",
    "Воспользуемся LSTM - он умеет работать с контекстом очень даже хорошо:\n",
    "\n",
    "![](https://image.ibb.co/kgmoff/Baseline-Tagger.png)\n",
    "\n",
    "Синим показано выделение фичей из слова, LSTM оранжевенький - он строит эмбеддинги слов с учетом контекста, а дальше зелененькая логистическая регрессия делает предсказания тегов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RtRbz1SwgEqc"
   },
   "outputs": [],
   "source": [
    "def convert_data(data, word2ind, tag2ind):\n",
    "    X = [[word2ind.get(word, 0) for word, _ in sample] for sample in data]\n",
    "    y = [[tag2ind[tag] for _, tag in sample] for sample in data]\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = convert_data(train_data, word2ind, tag2ind)\n",
    "X_val, y_val = convert_data(val_data, word2ind, tag2ind)\n",
    "X_test, y_test = convert_data(test_data, word2ind, tag2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DhsTKZalfih6"
   },
   "outputs": [],
   "source": [
    "def iterate_batches(data, batch_size):\n",
    "    X, y = data\n",
    "    n_samples = len(X)\n",
    "\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    for start in range(0, n_samples, batch_size):\n",
    "        end = min(start + batch_size, n_samples)\n",
    "        \n",
    "        batch_indices = indices[start:end]\n",
    "        \n",
    "        max_sent_len = max(len(X[ind]) for ind in batch_indices)\n",
    "        X_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
    "        y_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
    "        \n",
    "        for batch_ind, sample_ind in enumerate(batch_indices):\n",
    "            X_batch[:len(X[sample_ind]), batch_ind] = X[sample_ind]\n",
    "            y_batch[:len(y[sample_ind]), batch_ind] = y[sample_ind]\n",
    "            \n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l4XsRII5kW5x"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 4), (32, 4))"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch, y_batch = next(iterate_batches((X_train, y_train), 4))\n",
    "\n",
    "X_batch.shape, y_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C5I9E9P6eFYv"
   },
   "source": [
    "**Задание** Реализуйте `LSTMTagger`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WVEHju54d68T"
   },
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_layers = lstm_layers_count\n",
    "        self.hidden_size = lstm_hidden_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, word_emb_dim)\n",
    "        self.lstm = lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim, lstm_layers_count)\n",
    "        self.linear = nn.Linear(lstm_hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        embeds = self.embeddings(inputs)\n",
    "        output, hidden = self.lstm(embeds)\n",
    "        output = self.linear(output)\n",
    "\n",
    "        return output      \n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q_HA8zyheYGH"
   },
   "source": [
    "**Задание** Научитесь считать accuracy и loss (а заодно проверьте, что модель работает)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jbrxsZ2mehWB"
   },
   "outputs": [],
   "source": [
    "model = LSTMTagger(\n",
    "    vocab_size=len(word2ind),\n",
    "    tagset_size=len(tag2ind)\n",
    ")\n",
    "\n",
    "X_batch, y_batch = torch.LongTensor(X_batch), torch.LongTensor(y_batch)\n",
    "\n",
    "logits = model(X_batch)\n",
    "_, indices = torch.max(logits, 2)\n",
    "\n",
    "correct_samples =  torch.sum((indices == y_batch) & (y_batch != 0))\n",
    "total_samples = torch.sum(y_batch != 0)\n",
    "accuracy = correct_samples / total_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GMUyUm1hgpe3"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "loss = criterion(logits.view(-1, logits.shape[2]), y_batch.view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nSgV3NPUpcjH"
   },
   "source": [
    "**Задание** Вставьте эти вычисление в функцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FprPQ0gllo7b"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def do_epoch(model, criterion, data, batch_size, optimizer=None, name=None):\n",
    "    epoch_loss = 0\n",
    "    correct_count = 0\n",
    "    sum_count = 0\n",
    "    \n",
    "    is_train = not optimizer is None\n",
    "    name = name or ''\n",
    "    model.train(is_train)\n",
    "    \n",
    "    batches_count = math.ceil(len(data[0]) / batch_size)\n",
    "    \n",
    "    with torch.autograd.set_grad_enabled(is_train):\n",
    "        with tqdm(total=batches_count) as progress_bar:\n",
    "            for i, (X_batch, y_batch) in enumerate(iterate_batches(data, batch_size)):\n",
    "                X_batch, y_batch = LongTensor(X_batch), LongTensor(y_batch)\n",
    "                logits = model(X_batch)\n",
    "\n",
    "                loss = criterion(logits.view(-1, logits.shape[2]), y_batch.view(-1))\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                if optimizer:\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                _, indices = torch.max(logits, 2)\n",
    "                cur_correct_count = torch.sum((indices == y_batch)&(y_batch != 0))\n",
    "                cur_sum_count = torch.sum(y_batch != 0)\n",
    "\n",
    "                correct_count += cur_correct_count\n",
    "                sum_count += cur_sum_count\n",
    "\n",
    "                progress_bar.update()\n",
    "                progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
    "                    name, loss.item(), cur_correct_count / cur_sum_count)\n",
    "                )\n",
    "                \n",
    "            progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
    "                name, epoch_loss / batches_count, correct_count / sum_count)\n",
    "            )\n",
    "\n",
    "    return epoch_loss / batches_count, correct_count / sum_count\n",
    "\n",
    "\n",
    "def fit(model, criterion, optimizer, train_data, epochs_count=1, batch_size=32,\n",
    "        val_data=None, val_batch_size=None):\n",
    "        \n",
    "    if not val_data is None and val_batch_size is None:\n",
    "        val_batch_size = batch_size\n",
    "        \n",
    "    for epoch in range(epochs_count):\n",
    "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
    "        train_loss, train_acc = do_epoch(model, criterion, train_data, batch_size, optimizer, name_prefix + 'Train:')\n",
    "        \n",
    "        if not val_data is None:\n",
    "            val_loss, val_acc = do_epoch(model, criterion, val_data, val_batch_size, None, name_prefix + '  Val:')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pqfbeh1ltEYa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1 / 10] Train: Loss = 0.30945, Accuracy = 71.95%: 100%|██████████| 572/572 [01:41<00:00,  5.62it/s]\n",
      "[1 / 10]   Val: Loss = 0.10485, Accuracy = 84.91%: 100%|██████████| 13/13 [00:04<00:00,  2.86it/s]\n",
      "[2 / 10] Train: Loss = 0.09994, Accuracy = 90.01%: 100%|██████████| 572/572 [01:38<00:00,  5.79it/s]\n",
      "[2 / 10]   Val: Loss = 0.07209, Accuracy = 89.69%: 100%|██████████| 13/13 [00:05<00:00,  2.28it/s]\n",
      "[3 / 10] Train: Loss = 0.06742, Accuracy = 93.22%: 100%|██████████| 572/572 [01:35<00:00,  6.00it/s]\n",
      "[3 / 10]   Val: Loss = 0.06595, Accuracy = 91.20%: 100%|██████████| 13/13 [00:04<00:00,  2.75it/s]\n",
      "[4 / 10] Train: Loss = 0.05062, Accuracy = 94.84%: 100%|██████████| 572/572 [01:21<00:00,  7.02it/s]\n",
      "[4 / 10]   Val: Loss = 0.06323, Accuracy = 91.98%: 100%|██████████| 13/13 [00:04<00:00,  2.85it/s]\n",
      "[5 / 10] Train: Loss = 0.04064, Accuracy = 95.82%: 100%|██████████| 572/572 [01:20<00:00,  7.13it/s]\n",
      "[5 / 10]   Val: Loss = 0.06277, Accuracy = 92.49%: 100%|██████████| 13/13 [00:05<00:00,  2.47it/s]\n",
      "[6 / 10] Train: Loss = 0.03308, Accuracy = 96.55%: 100%|██████████| 572/572 [01:24<00:00,  6.77it/s]\n",
      "[6 / 10]   Val: Loss = 0.06097, Accuracy = 92.79%: 100%|██████████| 13/13 [00:05<00:00,  2.45it/s]\n",
      "[7 / 10] Train: Loss = 0.02758, Accuracy = 97.14%: 100%|██████████| 572/572 [01:29<00:00,  6.36it/s]\n",
      "[7 / 10]   Val: Loss = 0.06094, Accuracy = 92.95%: 100%|██████████| 13/13 [00:05<00:00,  2.37it/s]\n",
      "[8 / 10] Train: Loss = 0.02276, Accuracy = 97.61%: 100%|██████████| 572/572 [01:21<00:00,  7.02it/s]\n",
      "[8 / 10]   Val: Loss = 0.06274, Accuracy = 93.08%: 100%|██████████| 13/13 [00:05<00:00,  2.50it/s]\n",
      "[9 / 10] Train: Loss = 0.01893, Accuracy = 98.02%: 100%|██████████| 572/572 [01:30<00:00,  6.33it/s]\n",
      "[9 / 10]   Val: Loss = 0.07186, Accuracy = 93.12%: 100%|██████████| 13/13 [00:04<00:00,  2.82it/s]\n",
      "[10 / 10] Train: Loss = 0.01579, Accuracy = 98.35%: 100%|██████████| 572/572 [01:51<00:00,  5.12it/s]\n",
      "[10 / 10]   Val: Loss = 0.07415, Accuracy = 93.13%: 100%|██████████| 13/13 [00:06<00:00,  2.05it/s]\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTagger(\n",
    "    vocab_size=len(word2ind),\n",
    "    tagset_size=len(tag2ind)\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=10,\n",
    "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m0qGetIhfUE5"
   },
   "source": [
    "### Masking\n",
    "\n",
    "**Задание** Проверьте себя - не считаете ли вы потери и accuracy на паддингах - очень легко получить высокое качество за счет этого.\n",
    "\n",
    "У функции потерь есть параметр `ignore_index`, для таких целей. Для accuracy нужно использовать маскинг - умножение на маску из нулей и единиц, где нули на позициях паддингов (а потом усреднение по ненулевым позициям в маске)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nAfV2dEOfHo5"
   },
   "source": [
    "**Задание** Посчитайте качество модели на тесте. Ожидается результат лучше бейзлайна!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "98wr38_rw55D"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1 / 1] Train: Loss = 0.12027, Accuracy = 93.25%: 100%|██████████| 448/448 [00:12<00:00, 34.87it/s]\n"
     ]
    }
   ],
   "source": [
    "fit(model, criterion, None, train_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PXUTSFaEHbDG"
   },
   "source": [
    "### Bidirectional LSTM\n",
    "\n",
    "Благодаря BiLSTM можно использовать сразу оба контеста при предсказании тега слова. Т.е. для каждого токена $w_i$ forward LSTM будет выдавать представление $\\mathbf{f_i} \\sim (w_1, \\ldots, w_i)$ - построенное по всему левому контексту - и $\\mathbf{b_i} \\sim (w_n, \\ldots, w_i)$ - представление правого контекста. Их конкатенация автоматически захватит весь доступный контекст слова: $\\mathbf{h_i} = [\\mathbf{f_i}, \\mathbf{b_i}] \\sim (w_1, \\ldots, w_n)$.\n",
    "\n",
    "![BiLSTM](https://www.researchgate.net/profile/Wang_Ling/publication/280912217/figure/fig2/AS:391505383575555@1470353565299/Illustration-of-our-neural-network-for-POS-tagging.png)  \n",
    "*From [Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation](https://arxiv.org/abs/1508.02096)*\n",
    "\n",
    "**Задание** Добавьте Bidirectional LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1 / 10] Train: Loss = 0.24827, Accuracy = 76.82%: 100%|██████████| 572/572 [03:30<00:00,  2.72it/s]\n",
      "[1 / 10]   Val: Loss = 0.07066, Accuracy = 89.79%: 100%|██████████| 13/13 [00:12<00:00,  1.07it/s]\n",
      "[2 / 10] Train: Loss = 0.07585, Accuracy = 92.62%: 100%|██████████| 572/572 [03:28<00:00,  2.75it/s]\n",
      "[2 / 10]   Val: Loss = 0.04453, Accuracy = 93.63%: 100%|██████████| 13/13 [00:13<00:00,  1.06s/it]\n",
      "[3 / 10] Train: Loss = 0.04953, Accuracy = 95.30%: 100%|██████████| 572/572 [03:37<00:00,  2.63it/s]\n",
      "[3 / 10]   Val: Loss = 0.03468, Accuracy = 94.97%: 100%|██████████| 13/13 [00:15<00:00,  1.16s/it]\n",
      "[4 / 10] Train: Loss = 0.03489, Accuracy = 96.71%: 100%|██████████| 572/572 [03:42<00:00,  2.57it/s]\n",
      "[4 / 10]   Val: Loss = 0.03374, Accuracy = 95.63%: 100%|██████████| 13/13 [00:13<00:00,  1.07s/it]\n",
      "[5 / 10] Train: Loss = 0.02557, Accuracy = 97.61%: 100%|██████████| 572/572 [03:39<00:00,  2.60it/s]\n",
      "[5 / 10]   Val: Loss = 0.03019, Accuracy = 95.96%: 100%|██████████| 13/13 [00:13<00:00,  1.07s/it]\n",
      "[6 / 10] Train: Loss = 0.01853, Accuracy = 98.28%: 100%|██████████| 572/572 [03:35<00:00,  2.66it/s]\n",
      "[6 / 10]   Val: Loss = 0.03093, Accuracy = 96.21%: 100%|██████████| 13/13 [00:13<00:00,  1.04s/it]\n",
      "[7 / 10] Train: Loss = 0.01351, Accuracy = 98.78%: 100%|██████████| 572/572 [03:39<00:00,  2.60it/s]\n",
      "[7 / 10]   Val: Loss = 0.02740, Accuracy = 96.29%: 100%|██████████| 13/13 [00:14<00:00,  1.14s/it]\n",
      "[8 / 10] Train: Loss = 0.00930, Accuracy = 99.19%: 100%|██████████| 572/572 [03:13<00:00,  2.95it/s]\n",
      "[8 / 10]   Val: Loss = 0.03376, Accuracy = 96.37%: 100%|██████████| 13/13 [00:10<00:00,  1.24it/s]\n",
      "[9 / 10] Train: Loss = 0.00635, Accuracy = 99.47%: 100%|██████████| 572/572 [03:06<00:00,  3.06it/s]\n",
      "[9 / 10]   Val: Loss = 0.03094, Accuracy = 96.38%: 100%|██████████| 13/13 [00:11<00:00,  1.09it/s]\n",
      "[10 / 10] Train: Loss = 0.00410, Accuracy = 99.68%: 100%|██████████| 572/572 [03:17<00:00,  2.89it/s]\n",
      "[10 / 10]   Val: Loss = 0.03641, Accuracy = 96.45%: 100%|██████████| 13/13 [00:12<00:00,  1.02it/s]\n",
      "[1 / 1] Train: Loss = 0.05861, Accuracy = 96.50%: 100%|██████████| 448/448 [00:23<00:00, 18.70it/s]\n"
     ]
    }
   ],
   "source": [
    "class BidirectionalLSTMTagger(nn.Module):\n",
    "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_layers = lstm_layers_count\n",
    "        self.hidden_size = lstm_hidden_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, word_emb_dim)\n",
    "        self.lstm = lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim, lstm_layers_count, bidirectional=True)\n",
    "        self.linear = nn.Linear(2*lstm_hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        embeds = self.embeddings(inputs)\n",
    "        output, hidden = self.lstm(embeds)\n",
    "        output = self.linear(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "model = BidirectionalLSTMTagger(\n",
    "    vocab_size=len(word2ind),\n",
    "    tagset_size=len(tag2ind)\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=10,\n",
    "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)\n",
    "\n",
    "fit(model, criterion, None, train_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZTXmYGD_ANhm"
   },
   "source": [
    "### Предобученные эмбеддинги\n",
    "\n",
    "Мы знаем, какая клёвая вещь - предобученные эмбеддинги. При текущем размере обучающей выборки еще можно было учить их и с нуля - с меньшей было бы совсем плохо.\n",
    "\n",
    "Поэтому стандартный пайплайн - скачать эмбеддинги, засунуть их в сеточку. Запустим его:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uZpY_Q1xZ18h"
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "w2v_model = api.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KYogOoKlgtcf"
   },
   "source": [
    "Построим подматрицу для слов из нашей тренировочной выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VsCstxiO03oT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Know 38736 out of 45441 word embeddings\n"
     ]
    }
   ],
   "source": [
    "known_count = 0\n",
    "embeddings = np.zeros((len(word2ind), w2v_model.vectors.shape[1]))\n",
    "for word, ind in word2ind.items():\n",
    "    word = word.lower()\n",
    "    if word in w2v_model.vocab:\n",
    "        embeddings[ind] = w2v_model.get_vector(word)\n",
    "        known_count += 1\n",
    "        \n",
    "print('Know {} out of {} word embeddings'.format(known_count, len(word2ind)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcG7i-R8hbY3"
   },
   "source": [
    "**Задание** Сделайте модель с предобученной матрицей. Используйте `nn.Embedding.from_pretrained`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LxaRBpQd0pat"
   },
   "outputs": [],
   "source": [
    "class LSTMTaggerWithPretrainedEmbs(nn.Module):\n",
    "    def __init__(self, embeddings, tagset_size, lstm_hidden_dim=64, lstm_layers_count=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_layers = lstm_layers_count\n",
    "        self.hidden_size = lstm_hidden_dim\n",
    "        \n",
    "        weight = torch.FloatTensor(embeddings)\n",
    "        self.embeddings = nn.Embedding.from_pretrained(weight)\n",
    "\n",
    "        word_emb_dim = embeddings.shape[1]\n",
    "        self.lstm = lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim, lstm_layers_count)\n",
    "        self.linear = nn.Linear(lstm_hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        embeds = self.embeddings(inputs)\n",
    "        output, hidden = self.lstm(embeds)\n",
    "        output = self.linear(output)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EBtI6BDE-Fc7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1 / 10] Train: Loss = 0.75404, Accuracy = 78.02%: 100%|██████████| 572/572 [00:41<00:00, 13.85it/s]\n",
      "[1 / 10]   Val: Loss = 0.37353, Accuracy = 89.18%: 100%|██████████| 13/13 [00:03<00:00,  3.70it/s]\n",
      "[2 / 10] Train: Loss = 0.28767, Accuracy = 91.37%: 100%|██████████| 572/572 [00:38<00:00, 15.01it/s]\n",
      "[2 / 10]   Val: Loss = 0.25945, Accuracy = 91.96%: 100%|██████████| 13/13 [00:03<00:00,  4.21it/s]\n",
      "[3 / 10] Train: Loss = 0.21075, Accuracy = 93.44%: 100%|██████████| 572/572 [00:41<00:00, 13.65it/s]\n",
      "[3 / 10]   Val: Loss = 0.21084, Accuracy = 93.29%: 100%|██████████| 13/13 [00:03<00:00,  3.84it/s]\n",
      "[4 / 10] Train: Loss = 0.17286, Accuracy = 94.49%: 100%|██████████| 572/572 [00:42<00:00, 13.48it/s]\n",
      "[4 / 10]   Val: Loss = 0.18405, Accuracy = 94.11%: 100%|██████████| 13/13 [00:03<00:00,  3.48it/s]\n",
      "[5 / 10] Train: Loss = 0.15146, Accuracy = 95.09%: 100%|██████████| 572/572 [00:41<00:00, 13.83it/s]\n",
      "[5 / 10]   Val: Loss = 0.16867, Accuracy = 94.48%: 100%|██████████| 13/13 [00:03<00:00,  3.83it/s]\n",
      "[6 / 10] Train: Loss = 0.13782, Accuracy = 95.46%: 100%|██████████| 572/572 [00:42<00:00, 13.41it/s]\n",
      "[6 / 10]   Val: Loss = 0.15956, Accuracy = 94.75%: 100%|██████████| 13/13 [00:03<00:00,  3.76it/s]\n",
      "[7 / 10] Train: Loss = 0.12795, Accuracy = 95.74%: 100%|██████████| 572/572 [00:42<00:00, 13.34it/s]\n",
      "[7 / 10]   Val: Loss = 0.15420, Accuracy = 94.89%: 100%|██████████| 13/13 [00:03<00:00,  3.75it/s]\n",
      "[8 / 10] Train: Loss = 0.12061, Accuracy = 95.94%: 100%|██████████| 572/572 [00:41<00:00, 13.79it/s]\n",
      "[8 / 10]   Val: Loss = 0.14802, Accuracy = 95.07%: 100%|██████████| 13/13 [00:03<00:00,  3.66it/s]\n",
      "[9 / 10] Train: Loss = 0.11518, Accuracy = 96.08%: 100%|██████████| 572/572 [00:42<00:00, 13.42it/s]\n",
      "[9 / 10]   Val: Loss = 0.14461, Accuracy = 95.11%: 100%|██████████| 13/13 [00:03<00:00,  3.74it/s]\n",
      "[10 / 10] Train: Loss = 0.11056, Accuracy = 96.22%: 100%|██████████| 572/572 [00:41<00:00, 13.80it/s]\n",
      "[10 / 10]   Val: Loss = 0.14279, Accuracy = 95.18%: 100%|██████████| 13/13 [00:03<00:00,  3.63it/s]\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTaggerWithPretrainedEmbs(\n",
    "    embeddings=embeddings,\n",
    "    tagset_size=len(tag2ind)\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=10,\n",
    "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Ne_8f24h8kg"
   },
   "source": [
    "**Задание** Оцените качество модели на тестовой выборке. Обратите внимание, вовсе не обязательно ограничиваться векторами из урезанной матрицы - вполне могут найтись слова в тесте, которых не было в трейне и для которых есть эмбеддинги.\n",
    "\n",
    "Добейтесь качества лучше прошлых моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HPUuAPGhEGVR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1 / 1] Train: Loss = 0.14315, Accuracy = 95.19%: 100%|██████████| 448/448 [00:07<00:00, 60.44it/s]\n"
     ]
    }
   ],
   "source": [
    "fit(model, criterion, None, train_data=(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Week 06 - RNNs, part 2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "interpreter": {
   "hash": "06cbd125af9ddaa8b2c9a7e189cfd490fc4b8c598e6a36e5eed8eecc7c4f6954"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('dlcourse': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
